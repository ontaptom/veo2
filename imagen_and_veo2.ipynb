{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imagen, Flash-2.0 Flash exp - Image Genration and veo2 demo\n",
        "\n",
        "This notebook showcase how to:\n",
        "- use Imagen3 to generate our character\n",
        "- use Gemini 2.0 Flash exp - Image Generation capabilities to adapt our character to different scenes\n",
        "- use veo2 to generate clips based on those scenes\n",
        "- use moviepy to merge clips into a single video\n",
        "\n",
        "Before you execute commands in this notebook, **make sure to check out the pricing**.\n",
        "\n",
        "Image and video genration **might be quite expensive**."
      ],
      "metadata": {
        "id": "aYK7SAbNVNou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ontaptom/veo2/blob/main/imagen_and_veo2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\">"
      ],
      "metadata": {
        "id": "cAp-N-Hb6eMc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5gZzwS8Qg2b"
      },
      "outputs": [],
      "source": [
        "# not really necessary since this is already pre-isntalled in colab, but in case of issues, uncomment and install the packages\n",
        "\n",
        "# !pip install --upgrade --user google-cloud-aiplatform google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper function to display images in colab\n",
        "\n",
        "import typing\n",
        "import IPython.display\n",
        "from PIL import Image as PIL_Image\n",
        "from PIL import ImageOps as PIL_ImageOps\n",
        "\n",
        "def display_image(\n",
        "    image,\n",
        "    max_width: int = 600,\n",
        "    max_height: int = 350,\n",
        ") -> None:\n",
        "    pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
        "    if pil_image.mode != \"RGB\":\n",
        "        # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
        "        pil_image = pil_image.convert(\"RGB\")\n",
        "    image_width, image_height = pil_image.size\n",
        "    if max_width < image_width or max_height < image_height:\n",
        "        # Resize to display a smaller notebook image\n",
        "        pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
        "    IPython.display.display(pil_image)"
      ],
      "metadata": {
        "id": "YL1Iv0POQsf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Auth to google cloud\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "echM78jvSHLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set up project_id and location\n",
        "\n",
        "from vertexai.preview.vision_models import ImageGenerationModel\n",
        "import vertexai\n",
        "\n",
        "project = \"<your-project-id>\" # @param {type: \"string\"}\n",
        "location = \"us-central1\" # @param {type: \"string\"}\n",
        "vertexai.init(project=project, location=location)\n",
        "\n"
      ],
      "metadata": {
        "id": "tlM6GI8mQ_9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate our main character\n",
        "\n",
        "generation_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
        "\n",
        "prompt = \"A stylish raccoon in a hoodie and linen shorts, full body shot. high detail. on solid white background\" # @param {type: \"string\"}\n",
        "\n",
        "images = generation_model.generate_images(\n",
        "    prompt=prompt,\n",
        "    number_of_images=1,\n",
        "    aspect_ratio=\"16:9\",\n",
        "    negative_prompt=\"\",\n",
        "    person_generation=\"allow_adult\",\n",
        "    safety_filter_level=\"block_few\",\n",
        ")\n",
        "\n",
        "display_image(images[0])\n",
        "\n",
        "# Save the image locally in the Colab session\n",
        "images[0]._pil_image.save('base_image.png')"
      ],
      "metadata": {
        "id": "UCX73ImU0lyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save the generation locally\n",
        "\n",
        "# Save the image locally in the Colab session\n",
        "images[0]._pil_image.save('base_image.png')"
      ],
      "metadata": {
        "id": "HEbrxIoORw5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Specify name for the storage bucket\n",
        "\n",
        "# storage bucket will be used to store generated scenes images as well as video generations.\n",
        "# You can specify existing bucket or provide a unique name and the bucket in later command\n",
        "# will be provisioned for you.\n",
        "\n",
        "video_bucket  = \"<unique-bucket-name-or-your-existing-one>\" # @param {type: \"string\"}"
      ],
      "metadata": {
        "id": "JonoXA3xTLq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title check if bucket exist, if not - create it\n",
        "\n",
        "from google.cloud import storage\n",
        "\n",
        "# Create a storage client\n",
        "storage_client = storage.Client(project=project)\n",
        "\n",
        "# Check if bucket exists, create it if it doesn't\n",
        "try:\n",
        "    bucket = storage_client.get_bucket(video_bucket)\n",
        "    print(f\"Bucket {bucket.name} already exists.\")\n",
        "except Exception:\n",
        "    # Bucket doesn't exist, create it\n",
        "    bucket = storage_client.create_bucket(video_bucket)\n",
        "    print(f\"Bucket {bucket.name} created.\")"
      ],
      "metadata": {
        "id": "DUQX-1ghW9iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title imports and set up genai client\n",
        "\n",
        "from io import BytesIO\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.genai.types import GenerateVideosConfig\n",
        "import os\n",
        "import time\n",
        "from PIL import Image\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "# Set environment variables\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project\n",
        "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = location\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"\n",
        "genai_client = genai.Client()"
      ],
      "metadata": {
        "id": "s-CT0DdcK0Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title First scene: modify base image with gemini-2.0-flash image gen\n",
        "\n",
        "scene_1 = \"the raccoon is standing in his kitchen and doing the dishes, camera shows the kitchen in the background. aspect ratio 16:9\" # @param {type:\"string\"}\n",
        "\n",
        "filename = \"base_image.png\"\n",
        "input_image = Image.open(filename)\n",
        "\n",
        "contents_1 = (input_image,scene_1)\n",
        "\n",
        "# first scene request\n",
        "\n",
        "response = genai_client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    contents=contents_1,\n",
        "    config=types.GenerateContentConfig(\n",
        "      response_modalities=['Text','Image']\n",
        "    )\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "  if part.text is not None:\n",
        "    print(part.text)\n",
        "  elif part.inline_data is not None:\n",
        "    image = Image.open(BytesIO((part.inline_data.data)))\n",
        "    image.save('scene_1.png')\n",
        "    display(image)"
      ],
      "metadata": {
        "id": "X-gP7BOq1e38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Second scene: modify base image with gemini-2.0-flash image gen\n",
        "\n",
        "scene_2 = \"the raccoon is sitting at a couch with remote in his hand, and watching tv.\" # @param {type:\"string\"}\n",
        "\n",
        "contents_2 = (input_image,scene_2)\n",
        "\n",
        "# second scene request\n",
        "\n",
        "response = genai_client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    contents=contents_2,\n",
        "    config=types.GenerateContentConfig(\n",
        "      response_modalities=['Text','Image']\n",
        "    )\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "  if part.text is not None:\n",
        "    print(part.text)\n",
        "  elif part.inline_data is not None:\n",
        "    image = Image.open(BytesIO((part.inline_data.data)))\n",
        "    image.save('scene_2.png')\n",
        "    display(image)"
      ],
      "metadata": {
        "id": "Eg0-v99_Uliu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file\n",
        "blob = bucket.blob(\"scene_1.png\")  # Name in the bucket\n",
        "blob.upload_from_filename(\"scene_1.png\")  # Local file path\n",
        "\n",
        "print(f\"File uploaded to gs://{video_bucket}/scene_1.png\")\n",
        "\n",
        "image_path_1=f\"gs://{video_bucket}/scene_1.png\"\n",
        "\n",
        "# Upload the file\n",
        "blob = bucket.blob(\"scene_2.png\")  # Name in the bucket\n",
        "blob.upload_from_filename(\"scene_2.png\")  # Local file path\n",
        "\n",
        "print(f\"File uploaded to gs://{video_bucket}/scene_2.png\")\n",
        "\n",
        "image_path_2=f\"gs://{video_bucket}/scene_2.png\""
      ],
      "metadata": {
        "id": "8GUtWmyrZz3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate first video clip\n",
        "# Set your bucket path for the output video\n",
        "output_gcs_uri = f\"gs://{video_bucket}/output/\"\n",
        "\n",
        "# Generate video from local image\n",
        "prompt = \"The raccoon is doing the dishes, POV shot zooming out and showing the whole room\"  # @param {type:\"string\"}\n",
        "operation = genai_client.models.generate_videos(\n",
        "    model=\"veo-2.0-generate-001\",\n",
        "    prompt=prompt,\n",
        "    image=types.Image(\n",
        "        gcs_uri=image_path_1,\n",
        "        mime_type=\"image/png\",\n",
        "    ),\n",
        "    config=GenerateVideosConfig(\n",
        "        aspect_ratio=\"16:9\",\n",
        "        output_gcs_uri=output_gcs_uri,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Wait for completion\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = genai_client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    print(operation.result.generated_videos[0].video.uri)\n",
        "    videoclip_1 = operation.result.generated_videos[0].video.uri"
      ],
      "metadata": {
        "id": "KbJasqjiXI9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Preview the first clip\n",
        "\n",
        "# download the first clip to local filesystem\n",
        "!gsutil cp {videoclip_1} ./clip_1.mp4\n",
        "\n",
        "# Read the video file and encode it\n",
        "video_file = open('clip_1.mp4', 'rb')\n",
        "video_data = video_file.read()\n",
        "video_file.close()\n",
        "\n",
        "# Create a data URL\n",
        "data_url = \"data:video/mp4;base64,\" + base64.b64encode(video_data).decode()\n",
        "\n",
        "# Display with HTML\n",
        "HTML(f\"\"\"\n",
        "<video width=\"640\" height=\"360\" controls>\n",
        "  <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "_7NX3GVIMmb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate second video clip\n",
        "# Generate video from local image\n",
        "\n",
        "prompt = \"The raccoon is watching tv, looking bored.\"  # @param {type:\"string\"}\n",
        "\n",
        "operation = genai_client.models.generate_videos(\n",
        "    model=\"veo-2.0-generate-001\",\n",
        "    prompt=prompt,\n",
        "    image=types.Image(\n",
        "        gcs_uri=image_path_2,\n",
        "        mime_type=\"image/png\",\n",
        "    ),\n",
        "    config=GenerateVideosConfig(\n",
        "        aspect_ratio=\"16:9\",\n",
        "        output_gcs_uri=output_gcs_uri,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Wait for completion\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = genai_client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    print(operation.result.generated_videos[0].video.uri)\n",
        "    videoclip_2 = operation.result.generated_videos[0].video.uri"
      ],
      "metadata": {
        "id": "uWD4FOMiLpY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Preview the second clip\n",
        "\n",
        "# download the second clip to local filesystem\n",
        "!gsutil cp {videoclip_2} ./clip_2.mp4\n",
        "\n",
        "# Read the video file and encode it\n",
        "video_file = open('clip_2.mp4', 'rb')\n",
        "video_data = video_file.read()\n",
        "video_file.close()\n",
        "\n",
        "# Create a data URL\n",
        "data_url = \"data:video/mp4;base64,\" + base64.b64encode(video_data).decode()\n",
        "\n",
        "# Display with HTML\n",
        "HTML(f\"\"\"\n",
        "<video width=\"640\" height=\"360\" controls>\n",
        "  <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "bHpbbQMWMyXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install moviepy and do necessary imports\n",
        "\n",
        "!pip install moviepy\n",
        "\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips, CompositeVideoClip\n"
      ],
      "metadata": {
        "id": "pXU6MDbtb-1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create single long clip\n",
        "# Load the video clips\n",
        "clip1 = VideoFileClip(\"clip_1.mp4\")\n",
        "clip2 = VideoFileClip(\"clip_2.mp4\")\n",
        "\n",
        "# Create a crossfade transition (1 second)\n",
        "transition_duration = 1.0\n",
        "\n",
        "# Add fade effects to create a transition\n",
        "clip1 = clip1.fadeout(transition_duration)\n",
        "clip2 = clip2.fadein(transition_duration)\n",
        "\n",
        "# Create the final composite with overlap\n",
        "final_clip = concatenate_videoclips(\n",
        "    [clip1, clip2],\n",
        "    method=\"compose\",\n",
        "    padding=-transition_duration/2  # This creates the overlap for crossfade\n",
        ")\n",
        "\n",
        "# Write the result to a file\n",
        "output_file = \"merged_video.mp4\"\n",
        "final_clip.write_videofile(output_file, codec='libx264')\n",
        "\n",
        "# Close the clips to free up resources\n",
        "clip1.close()\n",
        "clip2.close()\n",
        "final_clip.close()\n",
        "\n",
        "# Display using the same code you had"
      ],
      "metadata": {
        "id": "SJp7WGAHdoR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Display the video\n",
        "\n",
        "# Read the video file and encode it\n",
        "with open(output_file, 'rb') as video_file:\n",
        "    video_data = video_file.read()\n",
        "\n",
        "# Create a data URL\n",
        "data_url = \"data:video/mp4;base64,\" + base64.b64encode(video_data).decode()\n",
        "\n",
        "# Display with HTML\n",
        "HTML(f\"\"\"\n",
        "<video width=\"640\" height=\"360\" controls>\n",
        "  <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "8hjdwivxdoUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ew0p45ZSdoXc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}